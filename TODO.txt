!run neuralpde with the old non experiment manager interface on the spm model generated 
    (programmatically fix the model possibly? I think I need to expand the derivatives so I need to figure out how to do that cleanly again.)
    ^ wasn't necessary

!Finish hooking up the experiment manager to the SPM example to finish the entire loop from 
    pybamm model spec -> (pybamm model gen + pybamm sim) -> NeuralPDE nn train -> compare pybamm sim to nn eval
    for the spm

!finish homogeneous mdf applied to diffeqflux fastchains

!make mdf heterogeneous

!from there, replace the neuralpde nn stuff with the multidimensional function interface I've been designing (put it in this repo for now for simplicity)

!start on next model

spme:
!fixed a lot of mtk generation stuff
!added correct tracking variable
!add dependent variable dependencies to a dict for easier parsing
!make the sim parsing go in reverse tensor order in general (since they use numpy's ordering I think)
!generalize parsing for any order of array

!get IfElse.ifelse to broadcast correctly
!add x to the concentration function generation in pybamm
!redo plotting and logging to loop over the given data

!figure out how to get pybamm to also output the variable values on the edge of the domains (needed for model eval/debugging)
  !add a ghost node to it from my side? I don't know that pybamm will allow me to add ghost nodes to neumann even though I want it 
    ! no, I figured out how to call the solution variable directly, and it does a very small amount of extrapolation

!add a num_pts input to the simulation to control fidelity

!evaluate the generated losses on the sim data (using the call functions) to validate that the equations are correct (IMPORTANT!)
    !need to make the interpolation higher order because the linear interpolation is failing on the 2nd order stuff
    !finished for spm
    !need to generalize this process and add the scale dependence
    !on a progression of num_pts resolutions to show that the loss is decreasing as resolution increases (up to a point)
        !(not doing, just testing that we get very low error on high res)
    still need to do for 3d dvs (need to figure out what the fourth scipy.interpolate variable is named after :z)


!add a simpler ifelse test case 
    !this works, so why doesn't the larger one?
    is it the derivatives through the Dx(concentration)??
        try this in the easy test case

!spme and beyond: isn't generating the boundary conditions for eps_c_e
    !this is because the boundary conditions are specified for c_e and not eps_c_e so the transpiler isn't noting them.
        !can I have it convert at the end? how does it know that it needs to convert that equation?
        !c_e is a Concentration and eps_c_e is a ConcentrationVariable, that's the main way it was distinguishing to write or not
        !but there are other Concentrations that I don't want to save. how do I know to save the c_e one?
    !I ended up making c_e be the primary variable and then everything works since it reads from c_e instead now. hooray!

!spme: why does the generated loss do so poorly?
    !try diving into each concatenation and doing the variables within each domain separately and then only doing one final concatenation at the end.
        !this 
    !strangely, the loss does fine in the separator region (or, most of it)????
    !the loss does really bad after the separator up to like 0.66
    !oops, the interpolator is incorrectly scaled in x direction because of the different lengths of the regions. gonna do a really high res interpolation and then resample it w/ lower freq
    !yay after rescaling it performs much better (aside from the transients at the sep boundary which the interpolation doesn't track well)
    !can we generate the pde eqs in terms of just concentration? the porosity makes it super high freq at the boundaries but we don't want that.
        !yes, we should do this. this might fix the issue for the neumann condition too
    yes, that works!  the loss is still pretty bad on the interpolation though.  can I have it use the sub-interpolations for each of the regions??
        this might be a micro optimization, should get it running on supercloud first.

!things to do to get it to run on supercloud:
    !make it run locally:
        !keep the same data format for now but make it use interpolated high resolution values instead of the entire high resolution blob
        !make sure it works with the c_e versus eps_c_e change
        !add abs(error) to the error plot, it's more useful (can still plot regular error too)
        !remove the log printouts
        !run it for a lil bit to make sure it can do a cycle or two
        !added endat semantics to run a slice of the hyperparameter experiments
        !added a serial queue mode for experiment manager
        !make a slurm-style script !(made it able to run serial)
    !make it run on cloud:
        !update julia packages
        !update the NeuralPDE git repo
        !download DFNExperiments & the slurm folder
        !run hyperparameter experiment via slurm launcher

!make pybamm spit out the indvars in the same order each time

SPMnoR: why is it outputting an @ ??? this is a very simple model, maybe it's not reading the variable number correctly.
!ReducedC: it wants to get the 'Discharge capacity [A.h]' (Q_Ah in other models) but the sim doesn't want to include that. can I pass in only the sim 
    !variables to the sim object? currently the variables I pass in is a superset (just whatever variables the pycall generation script passes back to me)
    !added a variable about whether to include Q or not

DFN blocks:
    figure out integration domain of each equation and then use the correct variable there. this might interfere with the interpolators? can I just set it to extrapolation is fine so I don't get all the domain errors?
        !extrapolation handled by wrapping in an extrapolation() interpolation struct
        handle the x / xn / xp discrepancy again. I think last time I just put the variable that corresponded to the integration domain of the equation in there? 
            so how do I figure that out programmatically. 
            so the correct way to do this is to define "subdomains" and integration domains for each equation.  
                we can default to having 
    figure out saving 3d blobs for reuse and plotting 3d blobs (basically just make sure both work still)



!ok just pick the subdomain one. it's "doing it right" and not a lot more work so let's go!
how to get the info to the neuralpde parser:
    the correct way is to include it in the PDESystem. that takes a more work so I'm just going to include it as kwargs in the discretization.
        !when this gets merged I will do it correctly but for the demo I will not
    the way I'm doing it is by passing in subdomain relations as a Dict{Symbol, Symbol} of subdomain -> domain for those symbols
    and the equation integration domains as a vector of tuples of the Symbols of integration
    if either is nothing then default to the old behavior within neuralpde

how to get the info out of PyBaMM:
    subdomain:
        if x_n, x_s, or x_p and x are in the variables we care about, then 
            add the subdomain relation to the end
            this won't work for larger stuff but we can hardcode it for now like the concatenation stuff is hardcoded

    integration vars:
        look at rhs's to figure out the integration domain
            does this interact poorly with the Dx_n stuff in the bc's, for instance???

within neuralpde parser/transformer:
    pass the subdomain & integration info to the build symbolic stuff
    dig in there to figure out exactly where things need to change. it's probably in the first sections where variables are assigned (in particular, cord 's)

get it to work within neuralpde first, then change the transpiler second 
    (less important, since I can manually add it for now. if I do it correctly, the loss_certificate should go down once I make the manual change and then I can automate it)

    get it to run inside neuralpde, then piece it apart
    get the info inside w/ kwargs
    surgical changes


why is the boundary/initial condition for phi_s_p different than the other ones? ic of 2 and bc of (0, 1) neumann
    make sure the DFN one is similar

add kwargs handling to StructGenerator to set the initial relative weights for the losses
    work around for now is to just add a non-kwarg function to the MiniMaxAdaptiveLoss

then start integration with the other models and fix errors/ expand design as they come up
    ongoing! lots of progress tho

collapse the concatenation terms so that it's just one concatenation term and then all the logic is combined so we only have to do one ifelse per equation
    (not strictly necessary but it would be a great optimization and for ease of understanding)
    !probably unnecessary now that the loss functions have a good test



